{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import Model\n",
    "from predict import load_data\n",
    "from utils import imsetshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['cPSNR_test', 'lpips1_alex_test', 'lpips1_vgg_test']\n",
    "\n",
    "models = {}\n",
    "\n",
    "config_file_path = \"../config/config.json\"\n",
    "with open(config_file_path, \"r\") as read_file:\n",
    "    config = json.load(read_file)\n",
    "\n",
    "checkpoint_dir = config[\"paths\"][\"checkpoint_dir\"]\n",
    "checkpoint_filename = 'HRNet.pth'\n",
    "\n",
    "for model_name in model_names:\n",
    "    run_subfolder = model_name\n",
    "    \n",
    "    checkpoint_file = os.path.join('..', checkpoint_dir, run_subfolder, checkpoint_filename)\n",
    "    assert os.path.isfile(checkpoint_file)\n",
    "\n",
    "    model = Model(config)\n",
    "    model.load_checkpoint(checkpoint_file=checkpoint_file)\n",
    "\n",
    "    # Add model to dictionary\n",
    "    models[model_name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, baseline_cpsnrs = load_data(config_file_path, val_proportion=0.10, top_k=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = models[model_name]\n",
    "    current_model_results = []\n",
    "\n",
    "    for imset in test_dataset:\n",
    "        sr, scPSNR = model(imset)\n",
    "        current_model_results.append((imset['lr'][0], imset['hr'], sr, scPSNR))\n",
    "\n",
    "    model_results[model_name] = current_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LPIPS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lpips\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lpips_values(model_name, loss_fn):\n",
    "    results = model_results[model_name]\n",
    "\n",
    "    model_hrs = [r[1] for r in results]\n",
    "    model_srs = [r[2] for r in results]\n",
    "\n",
    "    model_hrs_tensor = torch.stack(model_hrs).to(device)\n",
    "    model_srs_tensor = torch.tensor(model_srs).to(device)\n",
    "\n",
    "    # Normalize\n",
    "    model_hrs_normalized = (model_hrs_tensor - 0.5) * 2\n",
    "    model_srs_normalized = (model_srs_tensor - 0.5) * 2\n",
    "\n",
    "    # Convert to color\n",
    "    model_hrs_normalized = model_hrs_normalized.unsqueeze(1).repeat(1, 3, 1, 1)\n",
    "    model_srs_normalized = model_srs_normalized.unsqueeze(1).repeat(1, 3, 1, 1)\n",
    "\n",
    "    # Batch size of 10\n",
    "    batch_size = 10\n",
    "\n",
    "    all_lpips_values = []\n",
    "\n",
    "    for i in range(0, len(model_hrs_normalized), batch_size):\n",
    "        lpips_values = loss_fn(model_hrs_normalized[i:i+batch_size], model_srs_normalized[i:i+batch_size]).cpu().detach().numpy()\n",
    "        # add the values to the list\n",
    "        all_lpips_values.extend(lpips_values)\n",
    "\n",
    "    return all_lpips_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "model_lpips_values = {}\n",
    "\n",
    "# Free up CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_lpips_values[model_name] = compute_lpips_values(model_name, lpips_fn)\n",
    "\n",
    "    # Free up CUDA memory\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "model_lpips_values_vgg = {}\n",
    "\n",
    "# Free up CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "lpips_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_lpips_values_vgg[model_name] = compute_lpips_values(model_name, lpips_fn)\n",
    "\n",
    "    # Free up CUDA memory\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate image comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def generate_images(indices, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for idx, imset_index in enumerate(indices):\n",
    "        plt.figure(figsize=(20, 4), facecolor='white', dpi=300)\n",
    "\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.imshow(test_dataset[imset_index]['lr'][0])\n",
    "        plt.title('LR\\n\\n\\n')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.imshow(test_dataset[imset_index]['hr'])\n",
    "        plt.title('HR\\n\\n\\n')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot SR images from all models\n",
    "        for model_num, model_name in enumerate(model_results.keys(), start=3):\n",
    "            model_result = model_results[model_name][imset_index]\n",
    "\n",
    "            sr_image = model_result[2]\n",
    "            cPSNR = model_result[3]\n",
    "            lpips = model_lpips_values[model_name][imset_index].item()\n",
    "            lpips_vgg = model_lpips_values_vgg[model_name][imset_index].item()\n",
    "\n",
    "            plt.subplot(1, 5, model_num)\n",
    "            plt.imshow(sr_image)\n",
    "            plt.title(f'{model_name}\\ncPSNR: {cPSNR:.2f}\\nLPIPS (alex): {lpips:.4f}\\nLPIPS (vgg): {lpips_vgg:.4f}')\n",
    "            plt.axis('off')\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(f'{output_dir}/comparison_set_{idx}.png', bbox_inches='tight', facecolor='white', dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def adjust_brightness(sr_image, target_brightness):\n",
    "    current_brightness = np.mean(sr_image)\n",
    "    if current_brightness == 0:  # Prevent division by zero\n",
    "        return sr_image\n",
    "    factor = target_brightness / current_brightness\n",
    "    return np.clip(sr_image * factor, 0, 1)  # Ensure values remain within valid range\n",
    "\n",
    "def generate_adjusted_images(indices, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for idx, imset_index in enumerate(indices):\n",
    "        plt.figure(figsize=(20, 4), facecolor='white', dpi=300)\n",
    "\n",
    "        plt.subplot(1, 5, 1)\n",
    "        lr_image = test_dataset[imset_index]['lr'][0]\n",
    "        plt.imshow(lr_image)\n",
    "        plt.title('LR\\n\\n\\n')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 5, 2)\n",
    "        hr_image = test_dataset[imset_index]['hr']\n",
    "        plt.imshow(hr_image)\n",
    "        plt.title('HR\\n\\n\\n')\n",
    "        plt.axis('off')\n",
    "\n",
    "        hr_brightness = torch.mean(hr_image).item()\n",
    "\n",
    "        # Plot SR images from all models\n",
    "        for model_num, model_name in enumerate(model_results.keys(), start=3):\n",
    "            model_result = model_results[model_name][imset_index]\n",
    "\n",
    "            sr_image = model_result[2]\n",
    "            cPSNR = model_result[3]\n",
    "            lpips = model_lpips_values[model_name][imset_index].item()\n",
    "            lpips_vgg = model_lpips_values_vgg[model_name][imset_index].item()\n",
    "\n",
    "            adjusted_sr_image = adjust_brightness(sr_image, hr_brightness)\n",
    "            #print(hr_brightness, np.mean(sr_image), np.mean(adjusted_sr_image))\n",
    "\n",
    "            plt.subplot(1, 5, model_num)\n",
    "            plt.imshow(adjusted_sr_image)\n",
    "            plt.title(f'{model_name}\\ncPSNR: {cPSNR:.2f}\\nLPIPS (alex): {lpips:.4f}\\nLPIPS (vgg): {lpips_vgg:.4f}')\n",
    "            plt.axis('off')\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(f'{output_dir}/comparison_set_{idx}.png', bbox_inches='tight', facecolor='white', dpi=300)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "# Randomly select 10 image sets\n",
    "random_indices = sample(range(len(test_dataset)), 10)\n",
    "output_dir = '../images/random'\n",
    "generate_adjusted_images(random_indices, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 10 best and worst images for alexnet in respect to LPIPS\n",
    "lpips_values = model_lpips_values['lpips1_alex_test']\n",
    "\n",
    "# Sort the indices based on the LPIPS values - lower should be first\n",
    "sorted_indices = sorted(range(len(lpips_values)), key=lambda i: lpips_values[i])\n",
    "\n",
    "# Best 10\n",
    "best_indices = sorted_indices[:10]\n",
    "best_output_dir = '../images/alex_best'\n",
    "generate_adjusted_images(best_indices, best_output_dir)\n",
    "\n",
    "# Worst 10\n",
    "worst_indices = sorted_indices[-10:]\n",
    "worst_output_dir = '../images/alex_worst'\n",
    "generate_adjusted_images(worst_indices, worst_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 10 best and worst images for alexnet in respect to LPIPS\n",
    "lpips_values = model_lpips_values_vgg['lpips1_vgg_test']\n",
    "\n",
    "# Sort the indices based on the LPIPS values - lower should be first\n",
    "sorted_indices = sorted(range(len(lpips_values)), key=lambda i: lpips_values[i])\n",
    "\n",
    "# Best 10\n",
    "best_indices = sorted_indices[:10]\n",
    "best_output_dir = '../images/vgg_best'\n",
    "generate_adjusted_images(best_indices, best_output_dir)\n",
    "\n",
    "# Worst 10\n",
    "worst_indices = sorted_indices[-10:]\n",
    "worst_output_dir = '../images/vgg_worst'\n",
    "generate_adjusted_images(worst_indices, worst_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display average cPSNR and lpips for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_results_data = [r[3] for r in model_results[model_name]]\n",
    "    average_cPSNR = np.mean(model_results_data)\n",
    "\n",
    "    lpips_values = [v.item() for v in model_lpips_values[model_name]]\n",
    "    average_lpips = np.mean(lpips_values)\n",
    "\n",
    "    lpips_values_vgg = [v.item() for v in model_lpips_values_vgg[model_name]]\n",
    "    average_lpips_vgg = np.mean(lpips_values_vgg)\n",
    "\n",
    "    table_data.append([model_name, f'{average_cPSNR:.2f}', f'{average_lpips:.4f}', f'{average_lpips_vgg:.4f}'])\n",
    "\n",
    "print(tabulate(table_data, headers=[\"Model Name\", \"Average cPSNR\", \"Average LPIPS (alexnet)\", \"Average LPIPS (vgg)\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "highres-net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
